{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Bank Authentication Data Set](https://archive.ics.uci.edu/ml/datasets/banknote+authentication) from the UCI repository.\r\n",
    "\r\n",
    "The data consists of 5 columns:\r\n",
    "\r\n",
    "* variance of Wavelet Transformed image (continuous)\r\n",
    "* skewness of Wavelet Transformed image (continuous)\r\n",
    "* curtosis of Wavelet Transformed image (continuous)\r\n",
    "* entropy of image (continuous)\r\n",
    "* class (integer)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#data import\r\n",
    "df = pd.read_csv(r'D:\\\\Python files\\\\Udemy\\\\Python for data science\\\\Py-DS-ML-Bootcamp-master\\\\Study Projects\\\\Bank_Note\\\\bank_note_data.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image.Var</th>\n",
       "      <th>Image.Skew</th>\n",
       "      <th>Image.Curt</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Image.Var  Image.Skew  Image.Curt  Entropy  Class\n",
       "0    3.62160      8.6661     -2.8073 -0.44699      0\n",
       "1    4.54590      8.1674     -2.4586 -1.46210      0\n",
       "2    3.86600     -2.6383      1.9242  0.10645      0\n",
       "3    3.45660      9.5228     -4.0112 -3.59440      0\n",
       "4    0.32924     -4.4552      4.5718 -0.98880      0"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1372 entries, 0 to 1371\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Image.Var   1372 non-null   float64\n",
      " 1   Image.Skew  1372 non-null   float64\n",
      " 2   Image.Curt  1372 non-null   float64\n",
      " 3   Entropy     1372 non-null   float64\n",
      " 4   Class       1372 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 53.7 KB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df.describe().transpose()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Image.Var</th>\n",
       "      <td>1372.0</td>\n",
       "      <td>0.433735</td>\n",
       "      <td>2.842763</td>\n",
       "      <td>-7.0421</td>\n",
       "      <td>-1.773000</td>\n",
       "      <td>0.49618</td>\n",
       "      <td>2.821475</td>\n",
       "      <td>6.8248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image.Skew</th>\n",
       "      <td>1372.0</td>\n",
       "      <td>1.922353</td>\n",
       "      <td>5.869047</td>\n",
       "      <td>-13.7731</td>\n",
       "      <td>-1.708200</td>\n",
       "      <td>2.31965</td>\n",
       "      <td>6.814625</td>\n",
       "      <td>12.9516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image.Curt</th>\n",
       "      <td>1372.0</td>\n",
       "      <td>1.397627</td>\n",
       "      <td>4.310030</td>\n",
       "      <td>-5.2861</td>\n",
       "      <td>-1.574975</td>\n",
       "      <td>0.61663</td>\n",
       "      <td>3.179250</td>\n",
       "      <td>17.9274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entropy</th>\n",
       "      <td>1372.0</td>\n",
       "      <td>-1.191657</td>\n",
       "      <td>2.101013</td>\n",
       "      <td>-8.5482</td>\n",
       "      <td>-2.413450</td>\n",
       "      <td>-0.58665</td>\n",
       "      <td>0.394810</td>\n",
       "      <td>2.4495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>1372.0</td>\n",
       "      <td>0.444606</td>\n",
       "      <td>0.497103</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count      mean       std      min       25%      50%       75%  \\\n",
       "Image.Var   1372.0  0.433735  2.842763  -7.0421 -1.773000  0.49618  2.821475   \n",
       "Image.Skew  1372.0  1.922353  5.869047 -13.7731 -1.708200  2.31965  6.814625   \n",
       "Image.Curt  1372.0  1.397627  4.310030  -5.2861 -1.574975  0.61663  3.179250   \n",
       "Entropy     1372.0 -1.191657  2.101013  -8.5482 -2.413450 -0.58665  0.394810   \n",
       "Class       1372.0  0.444606  0.497103   0.0000  0.000000  0.00000  1.000000   \n",
       "\n",
       "                max  \n",
       "Image.Var    6.8248  \n",
       "Image.Skew  12.9516  \n",
       "Image.Curt  17.9274  \n",
       "Entropy      2.4495  \n",
       "Class        1.0000  "
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import seaborn as sns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "sns.countplot(x='Class', data=df)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Class', ylabel='count'>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# to plot corr of 'benign_0__mal_1'\r\n",
    "df.corr()['Class'][:-1].sort_values().plot(kind='bar')\r\n",
    "# [:,-1] to drop the last value\r\n",
    "# plot(kind='bar') to plot a graph\r\n",
    "# Observation: Entropy can be eliminated with reference to the bar plot below, as the correlation is very low."
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "plt.figure(figsize=(10,10))\r\n",
    "sns.heatmap(df.corr())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAJDCAYAAAAcrI56AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAueElEQVR4nO3deZgtdX3v+/cHBDFHBkFEwiCYA3EWkQfFaCKIBvEGyHEAVEIc2EavPl6FKF69IB7jJfFGDyhqdkBFNJDgUdwqUXACxSFsBhUQZdDIjBoEHBn6e/9Y1bpse3dXD9Vr1drvF089e9Vv1ar6du2m+7u/v6FSVUiSJPXZBqMOQJIkaalMaCRJUu+Z0EiSpN4zoZEkSb1nQiNJknrPhEaSJPWeCY0kSVo2Sd6f5NYkl63j/SQ5McnVSb6VZPfluK4JjSRJWk4fBPab4/1nArs02yrgvctxURMaSZK0bKrqfOC/5jjkQOBDNfB1YIsk2y71uiY0kiRpJW0HXDe0f33TtiT3WeoJ5nP3j6/12Qod+9EBLxl1COuFI2/YfNQhTLx3PuSnow5h4u160Q9HHcJ64Y6fX5uVvN5K/q7deOs/ehmDrqJpq6tq9Updf106T2gkSdLkaJKXpSQwNwA7DO1v37QtiQmNJEl9N3XvqCNYiDXAK5OcATwBuL2qblrqSU1oJEnSsklyOvBU4IFJrgeOBTYCqKr3AWcD+wNXA78AXrQc1zWhkSSp72pq1BH8RlUdOs/7Bfyfy31dZzlJkqTeM6GRJEm9Z5eTJEl9NzU+XU6jYoVGkiT1nhUaSZJ6rsZoUPCoWKGRJEm9Z4VGkqS+cwyNFRpJktR/VmgkSeo7x9BYoZEkSf1nhUaSpL7r18MpO2GFRpIk9Z4VGkmS+s4xNFZoJElS/1mhkSSp71yHxgqNJEnqPys0kiT1nM9yskIjSZImgAmNJEnqPbucJEnqOwcFW6GRJEn9Z4VGkqS+c1CwFRpJktR/VmgkSeo7H05phUaSJPWfFRpJkvrOMTRWaCRJUv9ZoZEkqe9ch8YKjSRJ6j8rNJIk9Z1jaKzQSJKk/rNCI0lS3zmGxgqNJEnqPys0kiT1XJUrBVuhkSRJvWdCI0mSes8uJ0mS+s5p21ZoJElS/1mhkSSp75y2bYVGkiT1nxUaSZL6zjE0VmgkSVL/WaGRJKnvplxYzwqNJEnqPSs0kiT1nWNorNBIkqT+s0IjSVLfuQ7N/BWaJBsm+chKBCNJkrQY81ZoqureJA9JsnFV3bUSQUmSpAVwDE3rLqdrgQuSrAF+Pt1YVe/oJCpJkqQFaDso+BrgU83xmw5ts0qyKsnaJGtP/tDpS49SkiSt29TUym1jqlWFpqqOW8hJq2o1sBrg7h9fW4uIS5IkqbVWFZokWyd5e5Kzk3xheus6OEmS1C9J9kvy3SRXJzl6lvd3TPLFJJck+VaS/Zfjum27nD4CXAnsDBwH/AC4cDkCkCRJSzQmXU5JNgROAp4JPAI4NMkjZhz2JuDfqupxwCHAe5bjFrRNaLaqqlOAu6vqvKp6MbDPcgQgSZImxp7A1VV1bTMz+gzgwBnHFLBZ83pz4MbluHDbWU53N3/elORZzcW3XI4AJEnS0lSNzcMptwOuG9q/HnjCjGPeDJyT5FXAfwP2XY4Lz1mhSbJR8/KtSTYHjgSOAk4GXrMcAUiSpP4YnsncbKsWeIpDgQ9W1fbA/sBpSZb8KKb5KjQ3NGvPnA7cUVWXAXsv9aKSJGkZreB06uGZzLO4AdhhaH/7pm3YS4D9mnN9LckmwAOBW5cS13wZ0cMZDP59E3BdkhOSPHEpF5QkSRPrQmCXJDsn2ZjBoN81M475IfA0gCQPBzYBfrTUC8+Z0FTVT6rqn6pqbwYDfa4F3pnkmiR/t9SLS5KkZVBTK7fNFUbVPcArgc8C32Ewm+nyJG9JckBz2JHAEUm+yaAH6K+raslr1rV+2nZV3ZjkFOA24LXAS4E3LjUASZI0OarqbODsGW3HDL2+AviT5b7uvAlN07f1FwwG8TwJ+AxwNHDucgcjSZIWYYwfSbBS5kxokvwLg+lU5zFYXO/5VfWrlQhMkiSprfkqNJ8BXlZVd65EMJIkaRHmGduyPphvUPCH1pXMJNm9m5AkSZIWpvWg4Fm8HDhiuQKRJEmL5Bia1s9y+j1VZTIjSZLGQqsKTZIALwAeWlVvSbIj8OCq+o9Oo5MkSfNzDE3rCs17gL0YTN0GuJPB48ElSZJGru0YmidU1e5JLgGoqtuaJY0lSZJGrm1Cc3eSDYECSLI1YH1LkqRx4KDg1l1OJwIfBx7UPMPpK8DbOotKkiRpAVpVaKrqI0kuYvB0zAAHVdV3Oo1MkiS1Y4Wm9SynLYFbGTwVc7pto6q6u6vAJEmS2mo7huZiYAcGT9oOsAVwc5JbgCOq6qJuwpMkSfNy2nbrMTTnAvtX1QOraivgmcCngFcwmNItSZI0Mm0TmidW1Wend6rqHGCvqvo6cN9OIpMkSe1MTa3cNqbadjndlOT1wBnN/sHALc1U7vH96iRJ0nqhbULzfOBY4Kxm/4KmbUPgecsfliRJas0xNK2nbf8YeNU63r56+cKRJElauLbTtrcGXgc8Ethkur2q9ukoLkmS1NYYj21ZKW0HBX8EuBLYGTgO+AFwYUcxSZIkLUjbMTRbVdUpSV5dVecB5yUxoZEkaRw4hqb9wymbP29K8izgRmDLbkKSJElamLYJzVuTbA4cCbwL2Ax4TWdRSZKk9hxD03qW06eal7cDe3cXjiRJ0sK1neW0M4Np2zsNf6aqDugmLEmSpPbadjmdBZwCfBJXBpYkabzY5dQ6oflVVZ3YaSSSJEmL1DahOSHJscA5wK+nG6vq4k6ikiRJ7VWNOoKRa5vQPBo4DNiH33Y5VbMvSZI0Um0TmucCD62qu7oMRpIkLYJjaFo/+uAyYIsO45AkSVq0thWaLYArm8cdDI+hcdq2JEmjZoWmdUJzbKdRSJIkLUHblYLP6zoQSZK0SD6ccu6EJsmdDGYz/d5bQFXVZp1EJUmStABzJjRVtelKBSJJkhbJMTStZzlJkiSNrbaDgiVJ0rhypWArNJIkqf+s0EiS1HeOobFCI0mS+s8KjSRJfWeFpvuE5kcHvKTrS6z3tl5zyqhDWC+c+YdPGXUIE+/7d+8y6hAm3pO3etioQ5A6YZeTJEnqPbucJEnqOx99YIVGkiT1nxUaSZJ6rqZcWM8KjSRJ6j0rNJIk9Z3Ttq3QSJKk/rNCI0lS3znLyQqNJElaPkn2S/LdJFcnOXodxzwvyRVJLk/yL8txXSs0kiT13ZjMckqyIXAS8HTgeuDCJGuq6oqhY3YB3gD8SVXdluRBy3FtKzSSJGm57AlcXVXXVtVdwBnAgTOOOQI4qapuA6iqW5fjwlZoJEnqu/GZ5bQdcN3Q/vXAE2YcsytAkguADYE3V9VnlnphExpJktRaklXAqqGm1VW1egGnuA+wC/BUYHvg/CSPrqqfLiUuExpJkvpuBSs0TfKyrgTmBmCHof3tm7Zh1wPfqKq7ge8n+R6DBOfCpcTlGBpJkrRcLgR2SbJzko2BQ4A1M445i0F1hiQPZNAFde1SL2yFRpKkvqvxmOVUVfckeSXwWQbjY95fVZcneQuwtqrWNO89I8kVwL3A31bVT5Z6bRMaSZK0bKrqbODsGW3HDL0u4LXNtmzscpIkSb1nhUaSpL4bn2nbI2OFRpIk9Z4VGkmS+m5MHn0wSlZoJElS71mhkSSp78oxNFZoJElS71mhkSSp7xxDY4VGkiT1nxUaSZJ6rlyHxgqNJEnqPys0kiT1nWNorNBIkqT+s0IjSVLfuQ6NFRpJktR/VmgkSeo7x9BYoZEkSf1nQiNJknrPLidJkvrOhfWs0EiSpP6zQiNJUt85KNgKjSRJ6j8rNJIk9Z0L61mhkSRJ/WeFRpKkvnMMjRUaSZLUf1ZoJEnquXIdGis0kiSp/6zQSJLUd46hsUIjSZL6zwqNJEl9Z4XGCo0kSeo/KzSSJPWdKwVboZEkSf1nQiNJknqvVZdTkq8A5wFfBi6oqjs7jUqSJLXnoODWFZrDgO8Czwa+mmRtkneu6+Akq5pj1n74lhuXI05JkqR1alWhqarvJ/kVcFez7Q08fI7jVwOrAW580t6mjZIkdais0LSr0CS5BjgL2AY4BXhUVe3XYVySJEmttZ22fSLwZOBQ4HHAeUnOr6prOotMkiS1Y4WmXYWmqk6oqucC+wIXAW8GvtdhXJIkSa21neX0jwwqNPcHvgocw2DGkyRJGrUpF9Zr2+X0NeAfquqWLoORJElajLbTtj8GPD3J/wOQZMcke3YXliRJam2qVm4bU20TmpOAvYDnN/t3Nm2SJEkj17bL6QlVtXuSSwCq6rYkG3cYlyRJamuMKycrpW2F5u4kGwIFkGRrwBFIkiRpLCxkHZqPAw9K8nfAc4A3dRaVJElqrcoKTduE5qMM1p95GhDgIMAZT5IkaSy0TWg+BhxUVVcCJNkWOBd4fFeBSZKklhxD03oMzVnAvyXZMMlOwGeBN3QVlCRJ0kK0fdr2Pzezms4CdgJeVlVf7TAuSZKk1uas0CR57fQGbALsCFwKPLFpkyRJozZGC+sl2S/Jd5NcneToOY57dpJKssdy3IL5KjSbztj/2DraJUnSeq5Z4uUk4OnA9cCFSdZU1RUzjtsUeDXwjeW69pwJTVUdN0uwDwB+Ws4RkyRpLNT4DAreE7i6qq4FSHIGcCBwxYzj/ifw98DfLteF5+tyOibJw5rX903yBeAa4JYk+y5XEJIkaSJsB1w3tH990/YbSXYHdqiqTy/nheeb5XQw8N3m9eHN8VsDfwa8bTkDkSRJi7SCY2iSrEqydmhb1TbMJBsA7wCOXO5bMN8YmruGupb+HDi9qu4FvpOk7Ro2kiRpQlTVamD1Ot6+AdhhaH/7pm3apsCjgC8lAXgwsCbJAVW1dilxzZeU/DrJoxisCrw3cNTQe3+wlAtLkqRlMj5PV7wQ2CXJzgwSmUOA50+/WVW3Aw+c3k/yJeCopSYzMH+X06sZPPbgSuCdVfX9JoD9gUuWenFJkjQ5quoe4JUMFuD9DvBvVXV5krckOaDLa883y+kbwMNmaT8bOLuroCRJUntjNMtp1hyhqo5Zx7FPXa7rtn30we9pRilLkiSN3KITGuDlyxaFJElavDFaKXhUFp3QVNURyxmIJEnSYrVKaDLwwiTHNPs7Jtmz29AkSVIrUyu4jam2FZr3AHsBhzb7dzJ4VoMkSdLItV0c7wlVtXuSSwCq6rYkG3cYlyRJammcZjmNStsKzd3NEzQLIMnWjHXhSZIkrU/aJjQnAh8HHpTk74Cv4LOcJEnSmGjV5VRVH0lyEfA0IMBBVfWdTiOTJEnt2GfSLqFJsiVwK3D6UNtGVXV3V4FJkiS11XZQ8MUMnp55G4MKzRbAzUluAY6oqou6CU+SJM3HQcHtx9CcC+xfVQ+sqq2AZwKfAl7BYEq3JEnSyLRNaJ5YVZ+d3qmqc4C9qurrwH07iUySJLXjwnqtu5xuSvJ64Ixm/2DglmYq9xh/eZIkaX3QNqF5PnAscFazf0HTtiHwvOUPS5IktVWWFlpP2/4x8Kp1vH318oUjSZK0cG2nbW8NvA54JLDJdHtV7dNRXJIkqS0rNK0HBX8EuBLYGTgO+AFwYUcxSZIkLUjbMTRbVdUpSV5dVecB5yUxoZEkaQw4hqZ9QjO9IvBNSZ4F3Ahs2U1IkiRJC9M2oXlrks2BI4F3AZsBr+ksKkmS1J4VmtaznD7VvLwd2Lu7cCRJkhau7SynnRlM295p+DNVdUA3YUmSpLYcQ9O+y+ks4BTgk1jYkiRJY6ZtQvOrqjqx00gkSZIWqW1Cc0KSY4FzgF9PN1bVxZ1EJUmSWrPLqX1C82jgMGAfftvlVM2+JEnSSLVNaJ4LPLSq7uoyGEmStHBWaNo/+uAyYIsO45AkSVq0thWaLYArm8cdDI+hcdq2JEmjVhl1BCPXNqE5drEXOPKGzRf7UbV05h8+ZdQhrBd+eeOXRx3CxLv9sBeNOoSJd+v3/MWnydR2peDzug5EkiQtjmNo5kloktzJYDbT770FVFVt1klUkiRJCzBnQlNVm65UIJIkaXFqyq7EtrOcJEmSxlbbQcGSJGlMOYbGCo0kSZoAVmgkSeq5ch0aKzSSJKn/rNBIktRzjqGxQiNJkiaACY0kSeo9u5wkSeo5F9azQiNJkiaAFRpJknquZnvq4nrGCo0kSeo9KzSSJPWcY2is0EiSpAlghUaSpJ6zQmOFRpIkTQArNJIk9ZyznKzQSJKkCWBCI0lSz9VUVmybT5L9knw3ydVJjp7l/dcmuSLJt5J8PslDluMemNBIkqRlkWRD4CTgmcAjgEOTPGLGYZcAe1TVY4CPAv+wHNc2oZEkqeeqsmLbPPYErq6qa6vqLuAM4MDfjbW+WFW/aHa/Dmy/HPfAhEaSJC2X7YDrhvavb9rW5SXAvy/HhZ3lJElSz9XUyl0rySpg1VDT6qpavYjzvBDYA/iz5YjLhEaSJLXWJC/rSmBuAHYY2t++afsdSfYF3gj8WVX9ejnisstJkiQtlwuBXZLsnGRj4BBgzfABSR4H/BNwQFXdulwXtkIjSVLPTc0/WHdFVNU9SV4JfBbYEHh/VV2e5C3A2qpaA7wduD9wZhKAH1bVAUu9tgmNJElaNlV1NnD2jLZjhl7v28V1TWgkSeq5FtOpJ55jaCRJUu9ZoZEkqefaPJJg0lmhkSRJvWeFRpKknqsadQSjZ4VGkiT1nhUaSZJ6zjE0VmgkSdIEsEIjSVLPjctKwaNkhUaSJPWeFRpJknrOlYKt0EiSpAlghUaSpJ5zHRorNJIkaQKY0EiSpN6zy0mSpJ5z2rYVGkmSNAGs0EiS1HNO27ZCI0mSJoAVGkmSes5p21ZoJEnSBGiV0CR5bps2SZK08qYqK7aNq7YVmje0bJMkSVpxc46hSfJMYH9guyQnDr21GXDPHJ9bBawC2GPLx/Lf77/T0iOVJEmzcpbT/BWaG4G1wK+Ai4a2NcCfr+tDVbW6qvaoqj1MZiRJUtfmrNBU1TeTXAb8eVWdukIxSZKkBRjnsS0rZd4xNFV1L7BDko1XIB5JkqQFa7sOzfeBC5KsAX4+3VhV7+gkKkmS1JrL0LRPaK5ptg2ATbsLR5IkaeFaJTRVdVzXgUiSpMVxDE3LhCbJF5mlolVV+yx7RJIkSQvUtsvpqKHXmwDPZo51aCRJ0spxHZr2XU4XzWi6IMl/dBCPJEnSgrXtctpyaHcD4PHA5p1EJEmStEBtu5wuYjCGJgy6mr4PvKSroCRJUntTow5gDLTtctq560AkSZIWa76HU74QSFWdNqP9MODeqvqXLoOTJEnzKxwUPN+jD14FfHyW9o8BRy5/OJIkSQs3X5fTRlX1s5mNVfXzJBt1FJMkSVqAKZ99MG+F5n5J/tvMxiSbAj6sUpIkjYX5EppTgI8mech0Q5KdgDOa9yRJ0ohNkRXbxtWcXU5V9f8l+RlwfpL7N80/A46vqvd2Hp0kSVIL807brqr3Ae9rupmoqjs7j0qSJLXmLKf5u5x+o6ruHE5mkuzeTUiSJEkL0zqhmcXLly0KSZK0aFMruI2rRSc0VXXEcgYiSZK0WK0Smgy8MMkxzf6OSfbsNjRJktRGkRXbxlXbCs17gL2AQ5v9O4GTOolIkiRpgdo+bfsJVbV7kksAquq2JC6sJ0nSGBjnsS0rpW2F5u4kGwIFkGRrvH+SJGlMtE1oTmTwkMoHJfk74CvA2zqLSpIkaQFadTlV1UeSXAQ8DQhwUFV9p9PIJElSK+PUZZJkP+AEYEPg5Ko6fsb79wU+BDwe+AlwcFX9YKnXbZXQJNkSuBU4fahto6q6e6kBSJKkydAMTzkJeDpwPXBhkjVVdcXQYS8Bbquq/57kEODvgYOXeu22XU4XAz8Cvgdc1bz+QZKLkzx+qUFIkqTFG6Np23sCV1fVtVV1F4OHWR8445gDgVOb1x8FnpZkyfPB2yY05wL7V9UDq2or4JnAp4BXMJjSLUmStB1w3dD+9U3brMdU1T3A7cBWS71w24TmiVX12emdqjoH2Kuqvg7cd6lBSJKkxZvKym1JViVZO7StGvXXD+3XobkpyesZlI5g0Nd1S9NXNk5jkSRJUoeqajWweh1v3wDsMLS/fdM22zHXJ7kPsDmDwcFL0rZC8/wmqLOabcembUPgeUsNQpIkLd4UWbFtHhcCuyTZuVmA9xBgzYxj1gCHN6+fA3yhqmqp96DttO0fA69ax9tXLzUISZLUf1V1T5JXAp9lUPR4f1VdnuQtwNqqWgOcApyW5GrgvxgkPUvWdtr21sDrgEcCmwwFvs9yBCFJkhZvyeWNZVRVZwNnz2g7Zuj1r4DnLvd123Y5fQS4EtgZOA74AYOykiRJ0si1TWi2qqpTgLur6ryqejFgdUaSpDEwtYLbuGo7y2l6ReCbkjwLuBHYspuQJEmSFqZtQvPWJJsDRwLvAjYDXtNZVJIkqbWppS+023ttZzl9qnl5O7B3d+FIkiQtXNtZTjszmLa90/BnquqAbsKSJEltjdMsp1Fp2+V0FoN5459kvMcESZKk9VDbhOZXVXVip5FIkiQtUtuE5oQkxwLnAL+ebqyqizuJSpIktWbXSfuE5tHAYQzWnpm+b4Vr0UiSpDHQNqF5LvDQqrqry2AkSdLCTTlru/VKwZcBW3QYhyRJ0qK1rdBsAVyZ5EJ+dwyN07YlSRqxKSzRtE1oju00CkmSpCVou1LweV0HIkmSFseF9eZJaJLcyez3KUBV1WadRCVJkrQAcyY0VbXpSgUiSZIWx1lO7cfQLNo7H/LTri+x3vv+3buMOoT1wu2HvWjUIUy8zU/7wKhDmHjnP+pNow5hvfCIUQewHuo8oZEkSd1ypeD269BIkiSNLSs0kiT1nLOcrNBIkqQJYIVGkqSec5aTFRpJkjQBTGgkSVLv2eUkSVLPOW3bCo0kSZoAVmgkSeo5KzRWaCRJ0gSwQiNJUs+V07at0EiSpP6zQiNJUs85hsYKjSRJmgBWaCRJ6jkrNFZoJEnSBLBCI0lSz9WoAxgDVmgkSVLvWaGRJKnnplyHxgqNJEnqPys0kiT1nLOcrNBIkqQJYEIjSZJ6zy4nSZJ6zi4nKzSSJGkCWKGRJKnnXFjPCo0kSZoAVmgkSeo5F9azQiNJkiaAFRpJknrOWU5WaCRJ0gSwQiNJUs85y8kKjSRJmgAmNJIk9dwUtWLbUiTZMsm5Sa5q/nzALMfsluRrSS5P8q0kB7c5twmNJElaKUcDn6+qXYDPN/sz/QL4q6p6JLAf8L+SbDHfiR1DI0lSz/VoltOBwFOb16cCXwJeP3xAVX1v6PWNSW4FtgZ+OteJrdBIkqSVsk1V3dS8vhnYZq6Dk+wJbAxcM9+JrdBIktRzKznLKckqYNVQ0+qqWj30/ueAB8/y0TcO71RVJVln6Em2BU4DDq+qeYtQJjSSJKm1JnlZPcf7+67rvSS3JNm2qm5qEpZb13HcZsCngTdW1dfbxGWXkyRJWilrgMOb14cDn5h5QJKNgY8DH6qqj7Y9sQmNJEk9N7WC2xIdDzw9yVXAvs0+SfZIcnJzzPOAPwX+OsmlzbbbfCe2y0mSJK2IqvoJ8LRZ2tcCL21efxj48ELPbUIjSVLPTWXUEYyeXU6SJKn3rNBIktRzS30kwSSwQiNJknrPCo0kST1nfcYKjSRJmgBWaCRJ6rkePZyyM1ZoJElS77Wq0CTZqlkMR5IkjRlnObWv0Hw9yZlJ9k/i8j2SJGmstE1odmXwZM3DgKuSvC3Jrt2FJUmS2qoV3MZVq4SmBs6tqkOBIxg8IfM/kpyXZK+ZxydZlWRtkrWn3XTjMocsSZL0u1qPoQFeyKBCcwvwKgaPAN8NOBPYefj4qlrNoKLDzX/61HFO6CRJ6j1nObWftv014DTgoKq6fqh9bZL3LX9YkiRJ7bVNaP64qirJZkk2rao7p9+oqr/vKDZJkqRW2iY0j0/yAWBTIEl+Cry4qi7qLDJJktSK07bbJzTvB15RVV8GSPJk4APAY7oKTJIkqa22Cc2908kMQFV9Jck9HcUkSZIWwPpM+4TmvCT/BJzO4L4dDHwpye4AVXVxR/FJkiTNq21C89jmz2NntD+OQYKzz7JFJEmSFsRp2y0Tmqrau+tAJEmSFqvtwnqbM6jO/GnTdB7wlqq6vavAJElSO+UomtbPcno/cCfwvGa7g8EsJ0mSpJFrO4bmj6rq2UP7xyW5tIN4JEnSAjmGpn2F5pfN2jMAJPkT4JfdhCRJkrQwbSs0fwN8qBlLA3AbgyduS5KkEXOl4BYJTZINgcOq6rFJNgOoqjs6j0ySJKmleROaqrp3urvJREaSpPFjfaZ9l9MlSdYAZwI/n26sqo91EpUkSdICtE1oNgF+wu+uCFyACY0kSSPmGJr2Cc3JVXXBcEMz00mSJGnk2k7bflfLNkmSpBU3Z4UmyV7Ak4Ctk7x26K3NgA27DEySJLXjwnrzdzltDNy/OW7TofY7gOd0FZQkSdJCzJnQVNV5wHlJPlhV/7lCMUmSpAXw4ZTtBwXfN8lqYKfhz1TVPuv8hCRJ0gppm9CcCbwPOBm4t7twJEnSQjmGpn1Cc09VvbfTSCRJkhapbULzySSvAD4O/Hq6sar+q5OoJElSa46haZ/QTD9Z+2+H2gp46PKGI0mStHCtEpqq2rnrQCRJ0uI4hmaelYKTvG7o9XNnvPe2roKSJElaiPkefXDI0Os3zHhvv2WORZIkLcJU1Ypt42q+hCbreD3bviRJ0kjMN4am1vF6tn1JkjQC/kKeP6F5bJI7GFRj7te8ptnfpNPIJEmSWprvWU4+UVuSpDE3ZY1m3jE0kiRJY8+ERpIk9V7blYIlSdKY8tEHVmgkSdIEsEIjSVLP+egDKzSSJGmFJNkyyblJrmr+fMAcx26W5Pok725zbhMaSZJ6bopasW2JjgY+X1W7AJ9v9tflfwLntz2xCY0kSVopBwKnNq9PBQ6a7aAkjwe2Ac5pe2LH0EiS1HM9muW0TVXd1Ly+mUHS8juSbAD8I/BCYN+2JzahkSRJrSVZBawaalpdVauH3v8c8OBZPvrG4Z2qqiSzZWKvAM6uquuT9s/BNqGRJKnnVnKWU5O8rJ7j/XVWVZLckmTbqropybbArbMcthfwlCSvAO4PbJzkZ1U113gbExpJkrRi1gCHA8c3f35i5gFV9YLp10n+GthjvmQGHBQsSVLvVdWKbUt0PPD0JFcxGB9zPECSPZKcvJQTW6GRJEkroqp+Ajxtlva1wEtnaf8g8ME25zahkSSp55ZhfZjes8tJkiT1nhUaSZJ6zmc5WaGRJEkToPMKza4X/bDrS6z3nrzVw0Ydwnrh1u+1X+BJi3P+o9406hAm3l9c9tZRhyB1wi4nSZJ6rkePPuiMXU6SJKn3rNBIktRzTtu2QiNJkiaAFRpJknpuGR5J0HtWaCRJUu9ZoZEkqedcWM8KjSRJmgBWaCRJ6jnXobFCI0mSJoAVGkmSes51aKzQSJKkCWCFRpKknnMdGis0kiRpAlihkSSp5xxDY4VGkiRNACs0kiT1nOvQWKGRJEkTwIRGkiT1nl1OkiT13JTTtq3QSJKk/rNCI0lSz1mfsUIjSZImgBUaSZJ6zoX1rNBIkqQJYIVGkqSes0JjhUaSJE0AKzSSJPVcuQ6NFRpJktR/VmgkSeo5x9BYoZEkSRPACo0kST1XVmis0EiSpP6zQiNJUs85y8kKjSRJmgAmNJIkqffscpIkqeectm2FRpIkTQArNJIk9ZyDgq3QSJKkCWCFRpKknnMMjRUaSZI0AazQSJLUcz76wAqNJEmaAFZoJEnquSlnOVmhkSRJ/WeFRpKknnMMjRUaSZK0QpJsmeTcJFc1fz5gHcftmOScJN9JckWSneY7twmNJEk9N1W1YtsSHQ18vqp2AT7f7M/mQ8Dbq+rhwJ7ArfOd2IRGkiStlAOBU5vXpwIHzTwgySOA+1TVuQBV9bOq+sV8J3YMjSRJPdejMTTbVNVNzeubgW1mOWZX4KdJPgbsDHwOOLqq7p3rxCY0kiSptSSrgFVDTauravXQ+58DHjzLR984vFNVlWS2TOw+wFOAxwE/BP4V+GvglLniapXQJHk18AHgTuDk5iJHV9U5bT4vSZImQ5O8rJ7j/X3X9V6SW5JsW1U3JdmW2cfGXA9cWlXXNp85C3gi8yQ0bcfQvLiq7gCeATwAOAw4fo6AVyVZm2TtXffc0fISkiRpMXo0KHgNcHjz+nDgE7MccyGwRZKtm/19gCvmO3HbhCbNn/sDp1XV5UNtv6eqVlfVHlW1x8b32azlJSRJ0oQ7Hnh6kquAfZt9kuyR5GSAZqzMUcDnk3ybQb7xz/OduO0YmouSnMNgcM4bkmwKTC34y5AkScuuL4OCq+onwNNmaV8LvHRo/1zgMQs5d9uE5iXAbsC1VfWLJFsCL1rIhSRJkrrSNqHZi8EAnZ8neSGwO3BCd2FJkqS2fDhl+zE07wV+keSxwJHANQxW8ZMkSRq5tgnNPVVVDFb4e3dVnQRs2l1YkiSprVrB/8ZV2y6nO5O8AXgh8KdJNgA26i4sSZKk9tomNAcDzwdeUlU3J9kReHt3YUmSpLaqnHjcKqGpqpuBdwzt/xDH0EiSpDHRagxNkicmuTDJz5LcleTeJLd3HZwkSZrfFLVi27hqOyj43cChwFXA/RgsfvOeroKSJElaiLYJDVV1NbBhVd1bVR8A9usuLEmS1FZVrdg2rtoOCv5Fko2BS5P8A3ATC0iGJEmSutQ2KTkM2BB4JfBzYAfg2V0FJUmS2nMMTftZTv/ZvPwlcFx34UiSJC3cnAlN89judaZjVbWgJ2FKkiR1Yb4Kzf8AtgGum9G+A3BzJxFJkqQFGefBuitlvjE07wRur6r/HN6A25v3JEmSRm6+Cs02VfXtmY1V9e0kO3UTkiRJWogpKzTzVmi2mOO9+y1jHJIkSYs2X0KzNskRMxuTvBS4qJuQJEnSQtQK/jeu5uty+r+Ajyd5Ab9NYPYANgb+ssO4JEmSWpszoamqW4AnJdkbeFTT/Omq+kLnkUmSpFac5dR+Yb0vAl/sOBZJkqRFafssJ0mSNKbG+ZEEK8UHTEqSpN6zQiNJUs85hsYKjSRJmgBWaCRJ6jlXCrZCI0mSJoAVGkmSes4xNFZoJEnSBDChkSRJvWeXkyRJPefCelZoJEnSBLBCI0lSzzko2AqNJEmaAFZoJEnqORfWs0IjSZImgBUaSZJ6rpzlZIVGkiT1nxUaSZJ6zjE0VmgkSdIEsEIjSVLPuQ6NFRpJkjQBrNBIktRzznKyQiNJkiaAFRpJknrOMTRWaCRJ0gQwoZEkSb1nl5MkST1nl5MVGkmSNAGs0EiS1HPWZ6zQSJKkCRD73X5fklVVtXrUcUwy73H3vMcrw/vcPe+x2rBCM7tVow5gPeA97p73eGV4n7vnPda8TGgkSVLvmdBIkqTeM6GZnX213fMed897vDK8z93zHmteDgqWJEm9Z4VGkiT1Xu8SmiQ/G4MYDk9y+oy2Byb5UZL7jiquxRqHewqQ5IlJvpHk0iTfSfLmpv3NSY4acXjLZlzuN0CSo5Jc2dzzC5P81QI/v1uS/buKrytJ7m2+5unt6HmOf2qSJ61UfJMuyYOTnJHkmiQXJTk7ya5JLht1bOovVwpenI8D/5jkD6rqF03bc4BPVtWv5/twkvtU1T2dRthPpwLPq6pvJtkQ+ONRBzTJkvwN8HRgz6q6I8lmwF8u4PP3AXYD9gDO7iTI7vyyqnZbwPFPBX4GfHXmG/7/vDBJwuBn6KlVdUjT9lhgm5EGpt7rXYVmWvMvpvOSfCLJtUmOT/KCJP+R5NtJ/qg57i+af/VfkuRzSbZp2rdOcm6Sy5OcnOQ/kzywee+FzXkuTfJPzS/X36iqO4DzgL8Yaj4EOH2O6705yWlJLgBOW4FbtGCjvKeNBwE3AVTVvVV1xSwxHpHk35Pcb7ZzJnluknc0x746ybXN64c2935sjMH9/r+Blzffz1TVHVV1avP5Hwyda48kX2pez/w+fgtwcHOdg7u9Y91rvu7jklzc/B08LMlOwN8Ar2m+zqck+WCS9yX5BvAPGVSqvp7kW0k+nuQBzfm+lOSE5nOXJdkzyQZJrkqydXPMBkmunt5fD+wN3F1V75tuqKpvAtdN7yfZKcmXm7+Hi9NUx5Jsm+T8ofv5lOb/+w82+99O8pqV/5I0Dnqb0DQey+AHzcOBw4Bdq2pP4GTgVc0xXwGeWFWPA84AXte0Hwt8oaoeCXwU2BEgycOBg4E/af4Fdy/wglmufTqDJIYkfwjsCnxhjusBPALYt6oOXfJX3p1R3tN3At9tfiG8LMkmw28meSXwfwAHATut45xfBp7SfOQpwE+SbNe8Pn9Rd6RbI7nfGVRjNq2qaxcR8/D38THAv1bVblX1r4s416jcL7/b5TScjP24qnYH3gscVVU/AN4HvLP5Or/cHLc98KSqei3wIeD1VfUY4NsM/m6m/UHz9/AK4P1VNQV8mN/+newLfLOqftTNlzp2HgVcNM8xtwJPb/4eDgZObNqfD3y2uZ+PBS5lUCXcrqoeVVWPBj7QQczqgb53OV1YVTcBJLkGOKdp/zaDfwXA4IfOvybZFtgY+H7T/mSa8npVfSbJbU3704DHAxcmAbgfg/+5Zvo08J7mF8PzgP9dVfcmWdf1ANZU1S+X+DV3bWT3tKrekuQjwDMY/OA6lEGpH+CvGPwL7qCqujvJrOesqpuT3D/JpsAOwL8Af8ogofnYEu5LV0b5PbxYffg+ns9cXU7T3ycXAf9jjnOc2fw/vzmwRVWd17SfCpw5dNzpAFV1fpLNkmwBvB/4BPC/gBfjL+GZNgLenWQ3Bgn5rk37hcD7k2wEnFVVlzZV2IcmeReDn8vnzHZCTb6+V2iGx6tMDe1P8dtk7V3Au5vM/WXA7/yrfxZh0Le7W7P9cVW9eeZBzQ/0zzD4hXIIzQ+tea7387Zf2AiN7J4CVNU1VfVeBr+UH5tkq+atbzOoymzf4pxfBV4EfJffVmz2Asaqy6kxkvvddDP9LMlD13GOe/jtz4eZ1+vD9/FSTP8d3Mvc/+hrex9mro1RVXUdcEuSfYA9gX9fWIi9djmDhHsurwFuYVCF2YNBIk9Vnc/gHyg3AB9M8ldVdVtz3JcYVDtP7iZsjbu+JzRtbM7gmx/g8KH2CxhUVkjyDOABTfvngeckeVDz3pZJHrKOc58OvJbBYLavzXO9SdLJPU3yrDQlBWAXBr9QftrsX8Lgl/mapotvrnN+GTiKQRfTJQwqHb+uqtuX8kWPUFffw/8vcFJTZaSpbE3PcvoBv/2l8+w5YrsT2HRBX00/rfPrbL6vbksy3dV5GIMxdtMOBkjyZOD2oe/Dkxl0PZ1ZVfd2EvV4+gJw3yS/eT5TkscwqKhO2xy4qemeOwzYsDnuIcAtVfXPDO7f7s1Yrw2q6n8DbwJ2X5kvQ+NmfUho3gycmeQi4MdD7ccBz8hgmuBzgZuBO5uBqG8CzknyLeBcYFuADAZe7jF0jnOBP2QwhmD6X2Hrut4keTPd3NPDGIyhuZTBgNMXDP+gr6qvMEhUPs2gC2XWczJIaHYAzm8+fx2DcSh99Wa6ud/vBb7IoGvqMgb3bWro3CckWcsgsVyXLwKPmGUcyribOYbm+HmO/yTwl82xT5nl/cOBtzf3ezcGg6Wn/SrJJQzG4bxkqH0NcH/Ws+6m5mflXwL7ZjBt+3IGyfXNQ4e9Bzg8yTeBh/HbathTgW829/Ng4ARgO+BLzc+NDwNvWImvQ+NnvV0pOIP1Yu6tqnuS7AW8d4HTODWD93Rleb/HXwazw46qqrWzvLcHg4HGsyVIkhao74OCl2JH4N+SbADcBRwx4ngmgfd0ZXm/eyqDhfxezuyz/SQtwnpboZEkSZNjfRhDI0mSJpwJjSRJ6j0TGkmS1HsmNJIkqfdMaCRJUu+Z0EiSpN77/wFzaDt3tCInOAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "X = df.drop('Class', axis=1).values\r\n",
    "y = df['Class'].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "scaler = MinMaxScaler()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "X_train = scaler.fit_transform(X_train)\r\n",
    "X_test = scaler.transform(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "X_train"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.71674275, 0.54637649, 0.32564568, 0.94697073],\n",
       "       [0.63581622, 0.27693533, 0.57835497, 0.69559271],\n",
       "       [0.5354196 , 0.77670328, 0.30506669, 0.72157724],\n",
       "       ...,\n",
       "       [0.79118621, 0.40966597, 0.32232079, 0.80529292],\n",
       "       [0.39438519, 0.55980576, 0.19617227, 0.70100112],\n",
       "       [0.52241381, 0.5920508 , 0.08532173, 0.72110714]])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "X_test"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.33901593, 0.98672618, 0.25725159, 0.08770925],\n",
       "       [0.87149976, 0.49968721, 0.24864223, 0.87783809],\n",
       "       [0.36313091, 0.26615931, 0.61570938, 0.78636306],\n",
       "       ...,\n",
       "       [0.39128428, 0.55020243, 0.57890697, 0.83257136],\n",
       "       [0.63911905, 0.77459411, 0.22732155, 0.81317094],\n",
       "       [0.68975762, 0.60407572, 0.34434444, 0.84950308]])"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "X_train.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1029, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "from tensorflow.keras.models import Sequential"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "model = Sequential()\r\n",
    "\r\n",
    "model.add(Dense(4, activation='relu'))\r\n",
    "\r\n",
    "model.add(Dense(2, activation='relu'))\r\n",
    "\r\n",
    "# Binary Classification Problem last activation should be sigmoid\r\n",
    "model.add(Dense(1, activation='sigmoid'))\r\n",
    "\r\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# This callback will stop the training when there is no improvement in the loss for three consecutive epochs.\r\n",
    "early_stop = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose=1, patience=25)\r\n",
    "# patience = 25 means that the 25 epochs more will run after the min has been established"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "model.fit(x=X_train, y=y_train, epochs = 600, validation_data=(X_test, y_test), callbacks=[early_stop])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/600\n",
      "33/33 [==============================] - 2s 12ms/step - loss: 0.6903 - val_loss: 0.6794\n",
      "Epoch 2/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6872 - val_loss: 0.6764\n",
      "Epoch 3/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6848 - val_loss: 0.6741\n",
      "Epoch 4/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6827 - val_loss: 0.6707\n",
      "Epoch 5/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6806 - val_loss: 0.6679\n",
      "Epoch 6/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6785 - val_loss: 0.6651\n",
      "Epoch 7/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6766 - val_loss: 0.6619\n",
      "Epoch 8/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6741 - val_loss: 0.6592\n",
      "Epoch 9/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6714 - val_loss: 0.6550\n",
      "Epoch 10/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6683 - val_loss: 0.6510\n",
      "Epoch 11/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6649 - val_loss: 0.6470\n",
      "Epoch 12/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6608 - val_loss: 0.6424\n",
      "Epoch 13/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6569 - val_loss: 0.6376\n",
      "Epoch 14/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6333\n",
      "Epoch 15/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6481 - val_loss: 0.6283\n",
      "Epoch 16/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6435 - val_loss: 0.6239\n",
      "Epoch 17/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6382 - val_loss: 0.6172\n",
      "Epoch 18/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6329 - val_loss: 0.6117\n",
      "Epoch 19/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6276 - val_loss: 0.6057\n",
      "Epoch 20/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6215 - val_loss: 0.5991\n",
      "Epoch 21/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6156 - val_loss: 0.5929\n",
      "Epoch 22/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6090 - val_loss: 0.5875\n",
      "Epoch 23/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6027 - val_loss: 0.5796\n",
      "Epoch 24/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5953 - val_loss: 0.5728\n",
      "Epoch 25/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5881 - val_loss: 0.5652\n",
      "Epoch 26/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5807 - val_loss: 0.5570\n",
      "Epoch 27/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5728 - val_loss: 0.5504\n",
      "Epoch 28/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5646 - val_loss: 0.5420\n",
      "Epoch 29/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5573 - val_loss: 0.5335\n",
      "Epoch 30/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5472 - val_loss: 0.5255\n",
      "Epoch 31/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5369 - val_loss: 0.5155\n",
      "Epoch 32/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5251 - val_loss: 0.5046\n",
      "Epoch 33/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5103 - val_loss: 0.4901\n",
      "Epoch 34/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4946 - val_loss: 0.4745\n",
      "Epoch 35/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4789 - val_loss: 0.4608\n",
      "Epoch 36/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4637 - val_loss: 0.4450\n",
      "Epoch 37/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4478 - val_loss: 0.4320\n",
      "Epoch 38/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4334 - val_loss: 0.4159\n",
      "Epoch 39/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4207 - val_loss: 0.4037\n",
      "Epoch 40/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4068 - val_loss: 0.3917\n",
      "Epoch 41/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3942 - val_loss: 0.3785\n",
      "Epoch 42/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3823 - val_loss: 0.3662\n",
      "Epoch 43/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3708 - val_loss: 0.3559\n",
      "Epoch 44/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3599 - val_loss: 0.3460\n",
      "Epoch 45/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3497 - val_loss: 0.3336\n",
      "Epoch 46/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3388 - val_loss: 0.3251\n",
      "Epoch 47/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3289 - val_loss: 0.3143\n",
      "Epoch 48/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3195 - val_loss: 0.3058\n",
      "Epoch 49/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3105 - val_loss: 0.2965\n",
      "Epoch 50/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.3018 - val_loss: 0.2900\n",
      "Epoch 51/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2936 - val_loss: 0.2803\n",
      "Epoch 52/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2849 - val_loss: 0.2727\n",
      "Epoch 53/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2771 - val_loss: 0.2642\n",
      "Epoch 54/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2705 - val_loss: 0.2574\n",
      "Epoch 55/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2633 - val_loss: 0.2508\n",
      "Epoch 56/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2562 - val_loss: 0.2429\n",
      "Epoch 57/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2503 - val_loss: 0.2364\n",
      "Epoch 58/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2437 - val_loss: 0.2305\n",
      "Epoch 59/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2378 - val_loss: 0.2249\n",
      "Epoch 60/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2324 - val_loss: 0.2177\n",
      "Epoch 61/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2264 - val_loss: 0.2142\n",
      "Epoch 62/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2217 - val_loss: 0.2069\n",
      "Epoch 63/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2165 - val_loss: 0.2025\n",
      "Epoch 64/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2110 - val_loss: 0.1977\n",
      "Epoch 65/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2065 - val_loss: 0.1926\n",
      "Epoch 66/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.2023 - val_loss: 0.1897\n",
      "Epoch 67/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1977 - val_loss: 0.1849\n",
      "Epoch 68/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1939 - val_loss: 0.1796\n",
      "Epoch 69/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1893 - val_loss: 0.1751\n",
      "Epoch 70/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1855 - val_loss: 0.1716\n",
      "Epoch 71/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1816 - val_loss: 0.1683\n",
      "Epoch 72/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1777 - val_loss: 0.1634\n",
      "Epoch 73/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1741 - val_loss: 0.1624\n",
      "Epoch 74/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1709 - val_loss: 0.1568\n",
      "Epoch 75/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1672 - val_loss: 0.1538\n",
      "Epoch 76/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1638 - val_loss: 0.1505\n",
      "Epoch 77/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1605 - val_loss: 0.1471\n",
      "Epoch 78/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1575 - val_loss: 0.1435\n",
      "Epoch 79/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1544 - val_loss: 0.1410\n",
      "Epoch 80/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1515 - val_loss: 0.1373\n",
      "Epoch 81/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1482 - val_loss: 0.1350\n",
      "Epoch 82/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1453 - val_loss: 0.1314\n",
      "Epoch 83/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1426 - val_loss: 0.1296\n",
      "Epoch 84/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1403 - val_loss: 0.1262\n",
      "Epoch 85/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1371 - val_loss: 0.1238\n",
      "Epoch 86/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1345 - val_loss: 0.1216\n",
      "Epoch 87/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1319 - val_loss: 0.1184\n",
      "Epoch 88/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1294 - val_loss: 0.1162\n",
      "Epoch 89/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1272 - val_loss: 0.1134\n",
      "Epoch 90/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1250 - val_loss: 0.1113\n",
      "Epoch 91/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1225 - val_loss: 0.1090\n",
      "Epoch 92/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1203 - val_loss: 0.1074\n",
      "Epoch 93/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1183 - val_loss: 0.1051\n",
      "Epoch 94/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1162 - val_loss: 0.1025\n",
      "Epoch 95/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1140 - val_loss: 0.1020\n",
      "Epoch 96/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.1123 - val_loss: 0.0998\n",
      "Epoch 97/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1100 - val_loss: 0.0976\n",
      "Epoch 98/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1084 - val_loss: 0.0955\n",
      "Epoch 99/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1070 - val_loss: 0.0938\n",
      "Epoch 100/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1047 - val_loss: 0.0917\n",
      "Epoch 101/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1027 - val_loss: 0.0905\n",
      "Epoch 102/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.1011 - val_loss: 0.0893\n",
      "Epoch 103/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0996 - val_loss: 0.0867\n",
      "Epoch 104/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0978 - val_loss: 0.0870\n",
      "Epoch 105/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0967 - val_loss: 0.0848\n",
      "Epoch 106/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0948 - val_loss: 0.0833\n",
      "Epoch 107/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0935 - val_loss: 0.0820\n",
      "Epoch 108/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0920 - val_loss: 0.0801\n",
      "Epoch 109/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0904 - val_loss: 0.0784\n",
      "Epoch 110/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0892 - val_loss: 0.0769\n",
      "Epoch 111/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0877 - val_loss: 0.0759\n",
      "Epoch 112/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0862 - val_loss: 0.0750\n",
      "Epoch 113/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0853 - val_loss: 0.0738\n",
      "Epoch 114/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0837 - val_loss: 0.0722\n",
      "Epoch 115/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0826 - val_loss: 0.0711\n",
      "Epoch 116/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0816 - val_loss: 0.0708\n",
      "Epoch 117/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0690\n",
      "Epoch 118/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0790 - val_loss: 0.0676\n",
      "Epoch 119/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0788 - val_loss: 0.0669\n",
      "Epoch 120/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0770 - val_loss: 0.0655\n",
      "Epoch 121/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0756 - val_loss: 0.0652\n",
      "Epoch 122/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0751 - val_loss: 0.0635\n",
      "Epoch 123/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0736 - val_loss: 0.0628\n",
      "Epoch 124/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0727 - val_loss: 0.0617\n",
      "Epoch 125/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0716 - val_loss: 0.0611\n",
      "Epoch 126/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0711 - val_loss: 0.0598\n",
      "Epoch 127/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0700 - val_loss: 0.0595\n",
      "Epoch 128/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0688 - val_loss: 0.0584\n",
      "Epoch 129/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0679 - val_loss: 0.0573\n",
      "Epoch 130/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0671 - val_loss: 0.0565\n",
      "Epoch 131/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0661 - val_loss: 0.0562\n",
      "Epoch 132/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0654 - val_loss: 0.0551\n",
      "Epoch 133/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0644 - val_loss: 0.0544\n",
      "Epoch 134/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0637 - val_loss: 0.0533\n",
      "Epoch 135/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0629 - val_loss: 0.0527\n",
      "Epoch 136/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0620 - val_loss: 0.0522\n",
      "Epoch 137/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0614 - val_loss: 0.0517\n",
      "Epoch 138/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0605 - val_loss: 0.0505\n",
      "Epoch 139/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0598 - val_loss: 0.0496\n",
      "Epoch 140/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0590 - val_loss: 0.0492\n",
      "Epoch 141/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0584 - val_loss: 0.0483\n",
      "Epoch 142/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0576 - val_loss: 0.0479\n",
      "Epoch 143/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0571 - val_loss: 0.0471\n",
      "Epoch 144/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0565 - val_loss: 0.0464\n",
      "Epoch 145/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0558 - val_loss: 0.0461\n",
      "Epoch 146/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0549 - val_loss: 0.0453\n",
      "Epoch 147/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0543 - val_loss: 0.0446\n",
      "Epoch 148/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0543 - val_loss: 0.0448\n",
      "Epoch 149/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0530 - val_loss: 0.0435\n",
      "Epoch 150/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0524 - val_loss: 0.0433\n",
      "Epoch 151/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0522 - val_loss: 0.0427\n",
      "Epoch 152/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0521 - val_loss: 0.0418\n",
      "Epoch 153/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0509 - val_loss: 0.0424\n",
      "Epoch 154/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0503 - val_loss: 0.0408\n",
      "Epoch 155/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0495 - val_loss: 0.0403\n",
      "Epoch 156/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0490 - val_loss: 0.0398\n",
      "Epoch 157/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0496 - val_loss: 0.0402\n",
      "Epoch 158/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0479 - val_loss: 0.0387\n",
      "Epoch 159/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0474 - val_loss: 0.0386\n",
      "Epoch 160/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0468 - val_loss: 0.0378\n",
      "Epoch 161/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0473 - val_loss: 0.0378\n",
      "Epoch 162/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0462 - val_loss: 0.0372\n",
      "Epoch 163/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0454 - val_loss: 0.0369\n",
      "Epoch 164/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0448 - val_loss: 0.0360\n",
      "Epoch 165/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0446 - val_loss: 0.0358\n",
      "Epoch 166/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0439 - val_loss: 0.0353\n",
      "Epoch 167/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0437 - val_loss: 0.0355\n",
      "Epoch 168/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0433 - val_loss: 0.0346\n",
      "Epoch 169/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0427 - val_loss: 0.0342\n",
      "Epoch 170/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0423 - val_loss: 0.0343\n",
      "Epoch 171/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0415 - val_loss: 0.0331\n",
      "Epoch 172/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0421 - val_loss: 0.0328\n",
      "Epoch 173/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0410 - val_loss: 0.0324\n",
      "Epoch 174/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0404 - val_loss: 0.0323\n",
      "Epoch 175/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0406 - val_loss: 0.0316\n",
      "Epoch 176/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0395 - val_loss: 0.0316\n",
      "Epoch 177/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0397 - val_loss: 0.0309\n",
      "Epoch 178/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0387 - val_loss: 0.0309\n",
      "Epoch 179/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0384 - val_loss: 0.0303\n",
      "Epoch 180/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0384 - val_loss: 0.0304\n",
      "Epoch 181/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0379 - val_loss: 0.0296\n",
      "Epoch 182/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0374 - val_loss: 0.0292\n",
      "Epoch 183/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0370 - val_loss: 0.0290\n",
      "Epoch 184/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0368 - val_loss: 0.0288\n",
      "Epoch 185/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0361 - val_loss: 0.0282\n",
      "Epoch 186/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0360 - val_loss: 0.0281\n",
      "Epoch 187/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0355 - val_loss: 0.0276\n",
      "Epoch 188/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0352 - val_loss: 0.0273\n",
      "Epoch 189/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0349 - val_loss: 0.0270\n",
      "Epoch 190/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0346 - val_loss: 0.0272\n",
      "Epoch 191/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0342 - val_loss: 0.0264\n",
      "Epoch 192/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0338 - val_loss: 0.0263\n",
      "Epoch 193/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0337 - val_loss: 0.0259\n",
      "Epoch 194/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0332 - val_loss: 0.0258\n",
      "Epoch 195/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0329 - val_loss: 0.0258\n",
      "Epoch 196/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0325 - val_loss: 0.0250\n",
      "Epoch 197/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0323 - val_loss: 0.0248\n",
      "Epoch 198/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0320 - val_loss: 0.0246\n",
      "Epoch 199/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0316 - val_loss: 0.0246\n",
      "Epoch 200/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0313 - val_loss: 0.0242\n",
      "Epoch 201/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0312 - val_loss: 0.0242\n",
      "Epoch 202/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0309 - val_loss: 0.0236\n",
      "Epoch 203/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0304 - val_loss: 0.0235\n",
      "Epoch 204/600\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0304 - val_loss: 0.0231\n",
      "Epoch 205/600\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0299 - val_loss: 0.0230\n",
      "Epoch 206/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0226\n",
      "Epoch 207/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0226\n",
      "Epoch 208/600\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0292 - val_loss: 0.0222\n",
      "Epoch 209/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0220\n",
      "Epoch 210/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0218\n",
      "Epoch 211/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0283 - val_loss: 0.0215\n",
      "Epoch 212/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0214\n",
      "Epoch 213/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0210\n",
      "Epoch 214/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0275 - val_loss: 0.0209\n",
      "Epoch 215/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0272 - val_loss: 0.0207\n",
      "Epoch 216/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0270 - val_loss: 0.0204\n",
      "Epoch 217/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0204\n",
      "Epoch 218/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0268 - val_loss: 0.0201\n",
      "Epoch 219/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0198\n",
      "Epoch 220/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0196\n",
      "Epoch 221/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0194\n",
      "Epoch 222/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0194\n",
      "Epoch 223/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0256 - val_loss: 0.0190\n",
      "Epoch 224/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0253 - val_loss: 0.0189\n",
      "Epoch 225/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0251 - val_loss: 0.0186\n",
      "Epoch 226/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0253 - val_loss: 0.0189\n",
      "Epoch 227/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0248 - val_loss: 0.0185\n",
      "Epoch 228/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0185\n",
      "Epoch 229/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.0180\n",
      "Epoch 230/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0241 - val_loss: 0.0178\n",
      "Epoch 231/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0244 - val_loss: 0.0180\n",
      "Epoch 232/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0246 - val_loss: 0.0174\n",
      "Epoch 233/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.0173\n",
      "Epoch 234/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0234 - val_loss: 0.0174\n",
      "Epoch 235/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.0173\n",
      "Epoch 236/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.0169\n",
      "Epoch 237/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.0168\n",
      "Epoch 238/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0226 - val_loss: 0.0167\n",
      "Epoch 239/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0226 - val_loss: 0.0167\n",
      "Epoch 240/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0226 - val_loss: 0.0162\n",
      "Epoch 241/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0228 - val_loss: 0.0163\n",
      "Epoch 242/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.0163\n",
      "Epoch 243/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0218 - val_loss: 0.0158\n",
      "Epoch 244/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0218 - val_loss: 0.0157\n",
      "Epoch 245/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0215 - val_loss: 0.0156\n",
      "Epoch 246/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.0155\n",
      "Epoch 247/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.0156\n",
      "Epoch 248/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0217 - val_loss: 0.0152\n",
      "Epoch 249/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0212 - val_loss: 0.0150\n",
      "Epoch 250/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0207 - val_loss: 0.0150\n",
      "Epoch 251/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0204 - val_loss: 0.0149\n",
      "Epoch 252/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.0150\n",
      "Epoch 253/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.0146\n",
      "Epoch 254/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0200 - val_loss: 0.0144\n",
      "Epoch 255/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0199 - val_loss: 0.0146\n",
      "Epoch 256/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.0142\n",
      "Epoch 257/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0142\n",
      "Epoch 258/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0140\n",
      "Epoch 259/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0138\n",
      "Epoch 260/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0191 - val_loss: 0.0137\n",
      "Epoch 261/600\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0192 - val_loss: 0.0136\n",
      "Epoch 262/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0190 - val_loss: 0.0136\n",
      "Epoch 263/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0194 - val_loss: 0.0143\n",
      "Epoch 264/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0138\n",
      "Epoch 265/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0188 - val_loss: 0.0134\n",
      "Epoch 266/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0133\n",
      "Epoch 267/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0129\n",
      "Epoch 268/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0184 - val_loss: 0.0128\n",
      "Epoch 269/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0179 - val_loss: 0.0129\n",
      "Epoch 270/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0178 - val_loss: 0.0126\n",
      "Epoch 271/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0178 - val_loss: 0.0126\n",
      "Epoch 272/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0176 - val_loss: 0.0130\n",
      "Epoch 273/600\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0180 - val_loss: 0.0123\n",
      "Epoch 274/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0172 - val_loss: 0.0125\n",
      "Epoch 275/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0172 - val_loss: 0.0122\n",
      "Epoch 276/600\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0121\n",
      "Epoch 277/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0168 - val_loss: 0.0122\n",
      "Epoch 278/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0169 - val_loss: 0.0119\n",
      "Epoch 279/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0168 - val_loss: 0.0119\n",
      "Epoch 280/600\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0116\n",
      "Epoch 281/600\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0119\n",
      "Epoch 282/600\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0170 - val_loss: 0.0115\n",
      "Epoch 283/600\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0115\n",
      "Epoch 284/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0167 - val_loss: 0.0114\n",
      "Epoch 285/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0165 - val_loss: 0.0112\n",
      "Epoch 286/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0164 - val_loss: 0.0120\n",
      "Epoch 287/600\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0167 - val_loss: 0.0117\n",
      "Epoch 288/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0162 - val_loss: 0.0113\n",
      "Epoch 289/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0156 - val_loss: 0.0109\n",
      "Epoch 290/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0155 - val_loss: 0.0108\n",
      "Epoch 291/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0157 - val_loss: 0.0111\n",
      "Epoch 292/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0156 - val_loss: 0.0106\n",
      "Epoch 293/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0154 - val_loss: 0.0105\n",
      "Epoch 294/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0152 - val_loss: 0.0105\n",
      "Epoch 295/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0153 - val_loss: 0.0105\n",
      "Epoch 296/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0150 - val_loss: 0.0103\n",
      "Epoch 297/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.0103\n",
      "Epoch 298/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0147 - val_loss: 0.0103\n",
      "Epoch 299/600\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0101\n",
      "Epoch 300/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0147 - val_loss: 0.0100\n",
      "Epoch 301/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0173 - val_loss: 0.0101\n",
      "Epoch 302/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0146 - val_loss: 0.0100\n",
      "Epoch 303/600\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0143 - val_loss: 0.0099\n",
      "Epoch 304/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0102\n",
      "Epoch 305/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0098\n",
      "Epoch 306/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0098\n",
      "Epoch 307/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0097\n",
      "Epoch 308/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0096\n",
      "Epoch 309/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0096\n",
      "Epoch 310/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0094\n",
      "Epoch 311/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0097\n",
      "Epoch 312/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0095\n",
      "Epoch 313/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0094\n",
      "Epoch 314/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0091\n",
      "Epoch 315/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0094\n",
      "Epoch 316/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0091\n",
      "Epoch 317/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0093\n",
      "Epoch 318/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0089\n",
      "Epoch 319/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0089\n",
      "Epoch 320/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0089\n",
      "Epoch 321/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0087\n",
      "Epoch 322/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0090\n",
      "Epoch 323/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0088\n",
      "Epoch 324/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0085\n",
      "Epoch 325/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0091\n",
      "Epoch 326/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0087\n",
      "Epoch 327/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0085\n",
      "Epoch 328/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0086\n",
      "Epoch 329/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0083\n",
      "Epoch 330/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0088\n",
      "Epoch 331/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0083\n",
      "Epoch 332/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0087\n",
      "Epoch 333/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0082\n",
      "Epoch 334/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0120 - val_loss: 0.0083\n",
      "Epoch 335/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0081\n",
      "Epoch 336/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0079\n",
      "Epoch 337/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0082\n",
      "Epoch 338/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0083\n",
      "Epoch 339/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0080\n",
      "Epoch 340/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0080\n",
      "Epoch 341/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0077\n",
      "Epoch 342/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0078\n",
      "Epoch 343/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0079\n",
      "Epoch 344/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0078\n",
      "Epoch 345/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0075\n",
      "Epoch 346/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.0077\n",
      "Epoch 347/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0077\n",
      "Epoch 348/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.0075\n",
      "Epoch 349/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 350/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0078\n",
      "Epoch 351/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0108 - val_loss: 0.0073\n",
      "Epoch 352/600\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0111 - val_loss: 0.0071\n",
      "Epoch 353/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0109 - val_loss: 0.0072\n",
      "Epoch 354/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.0075\n",
      "Epoch 355/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.0070\n",
      "Epoch 356/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.0070\n",
      "Epoch 357/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.0071\n",
      "Epoch 358/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.0071\n",
      "Epoch 359/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.0069\n",
      "Epoch 360/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.0070\n",
      "Epoch 361/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.0072\n",
      "Epoch 362/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0103 - val_loss: 0.0068\n",
      "Epoch 363/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.0067\n",
      "Epoch 364/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0102 - val_loss: 0.0072\n",
      "Epoch 365/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0110 - val_loss: 0.0076\n",
      "Epoch 366/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.0067\n",
      "Epoch 367/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.0065\n",
      "Epoch 368/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.0065\n",
      "Epoch 369/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.0070\n",
      "Epoch 370/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0099 - val_loss: 0.0065\n",
      "Epoch 371/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0097 - val_loss: 0.0068\n",
      "Epoch 372/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.0064\n",
      "Epoch 373/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0098 - val_loss: 0.0064\n",
      "Epoch 374/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0097 - val_loss: 0.0063\n",
      "Epoch 375/600\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0064\n",
      "Epoch 376/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.0073\n",
      "Epoch 377/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.0063\n",
      "Epoch 378/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0094 - val_loss: 0.0061\n",
      "Epoch 379/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0093 - val_loss: 0.0070\n",
      "Epoch 380/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0098 - val_loss: 0.0060\n",
      "Epoch 381/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0070\n",
      "Epoch 382/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0097 - val_loss: 0.0065\n",
      "Epoch 383/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0094 - val_loss: 0.0062\n",
      "Epoch 384/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.0063\n",
      "Epoch 385/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0059\n",
      "Epoch 386/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.0058\n",
      "Epoch 387/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0058\n",
      "Epoch 388/600\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0057\n",
      "Epoch 389/600\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0059\n",
      "Epoch 390/600\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0057\n",
      "Epoch 391/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0056\n",
      "Epoch 392/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0062\n",
      "Epoch 393/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0056\n",
      "Epoch 394/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0056\n",
      "Epoch 395/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0057\n",
      "Epoch 396/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0056\n",
      "Epoch 397/600\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0058\n",
      "Epoch 398/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0058\n",
      "Epoch 399/600\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0057\n",
      "Epoch 400/600\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0053\n",
      "Epoch 401/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0054\n",
      "Epoch 402/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0056\n",
      "Epoch 403/600\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0053\n",
      "Epoch 404/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0052\n",
      "Epoch 405/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0052\n",
      "Epoch 406/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0052\n",
      "Epoch 407/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0053\n",
      "Epoch 408/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0054\n",
      "Epoch 409/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0052\n",
      "Epoch 410/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0054\n",
      "Epoch 411/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0079 - val_loss: 0.0053\n",
      "Epoch 412/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0050\n",
      "Epoch 413/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0049\n",
      "Epoch 414/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0050\n",
      "Epoch 415/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0051\n",
      "Epoch 416/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0051\n",
      "Epoch 417/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.0048\n",
      "Epoch 418/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0050\n",
      "Epoch 419/600\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0075 - val_loss: 0.0050\n",
      "Epoch 420/600\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0049\n",
      "Epoch 421/600\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0048\n",
      "Epoch 422/600\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0047\n",
      "Epoch 423/600\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0051\n",
      "Epoch 424/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0049\n",
      "Epoch 425/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0050\n",
      "Epoch 426/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0049\n",
      "Epoch 427/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0090 - val_loss: 0.0045\n",
      "Epoch 428/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.0047\n",
      "Epoch 429/600\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0050\n",
      "Epoch 430/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0045\n",
      "Epoch 431/600\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0071 - val_loss: 0.0048\n",
      "Epoch 432/600\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0072 - val_loss: 0.0045\n",
      "Epoch 433/600\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0070 - val_loss: 0.0048\n",
      "Epoch 434/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 435/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 436/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0050\n",
      "Epoch 437/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0071 - val_loss: 0.0043\n",
      "Epoch 438/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0068 - val_loss: 0.0044\n",
      "Epoch 439/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 440/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0043\n",
      "Epoch 441/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0068 - val_loss: 0.0046\n",
      "Epoch 442/600\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0066 - val_loss: 0.0043\n",
      "Epoch 443/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0066 - val_loss: 0.0043\n",
      "Epoch 444/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0066 - val_loss: 0.0046\n",
      "Epoch 445/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0067 - val_loss: 0.0045\n",
      "Epoch 446/600\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0069 - val_loss: 0.0045\n",
      "Epoch 447/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0067 - val_loss: 0.0044\n",
      "Epoch 448/600\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0065 - val_loss: 0.0045\n",
      "Epoch 449/600\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0064 - val_loss: 0.0040\n",
      "Epoch 450/600\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0064 - val_loss: 0.0043\n",
      "Epoch 451/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0064 - val_loss: 0.0041\n",
      "Epoch 452/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0064 - val_loss: 0.0042\n",
      "Epoch 453/600\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0065 - val_loss: 0.0039\n",
      "Epoch 454/600\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0066 - val_loss: 0.0041\n",
      "Epoch 455/600\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0063 - val_loss: 0.0039\n",
      "Epoch 456/600\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0063 - val_loss: 0.0041\n",
      "Epoch 457/600\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0066 - val_loss: 0.0048\n",
      "Epoch 458/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0065 - val_loss: 0.0040\n",
      "Epoch 459/600\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 0.0040\n",
      "Epoch 460/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0062 - val_loss: 0.0041\n",
      "Epoch 461/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0065 - val_loss: 0.0039\n",
      "Epoch 462/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0041\n",
      "Epoch 463/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0039\n",
      "Epoch 464/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0040\n",
      "Epoch 465/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0040\n",
      "Epoch 466/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0040\n",
      "Epoch 467/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0037\n",
      "Epoch 468/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 469/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0038\n",
      "Epoch 470/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0058 - val_loss: 0.0038\n",
      "Epoch 471/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0037\n",
      "Epoch 472/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0036\n",
      "Epoch 473/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0038\n",
      "Epoch 474/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0036\n",
      "Epoch 475/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0038\n",
      "Epoch 476/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 477/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0036\n",
      "Epoch 478/600\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0056 - val_loss: 0.0036\n",
      "Epoch 479/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0034\n",
      "Epoch 480/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0036\n",
      "Epoch 481/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0039\n",
      "Epoch 482/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0036\n",
      "Epoch 483/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0039\n",
      "Epoch 484/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0034\n",
      "Epoch 485/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 486/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0034\n",
      "Epoch 487/600\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 488/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0055 - val_loss: 0.0035\n",
      "Epoch 489/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0033\n",
      "Epoch 490/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 491/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0037\n",
      "Epoch 492/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0033\n",
      "Epoch 493/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 494/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0034\n",
      "Epoch 495/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0032\n",
      "Epoch 496/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 497/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0053 - val_loss: 0.0032\n",
      "Epoch 498/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0033\n",
      "Epoch 499/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0034\n",
      "Epoch 500/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 501/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 502/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 503/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 504/600\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 505/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 506/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 507/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 508/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 509/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 510/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0034\n",
      "Epoch 511/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0030\n",
      "Epoch 512/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0030\n",
      "Epoch 513/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 514/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 515/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0029\n",
      "Epoch 516/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 517/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 518/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0029\n",
      "Epoch 519/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0029\n",
      "Epoch 520/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 521/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 522/600\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 523/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 524/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 525/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0028\n",
      "Epoch 526/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0029\n",
      "Epoch 527/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 528/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 529/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 530/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 531/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 532/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 533/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 534/600\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 535/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 536/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 537/600\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 538/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 539/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 540/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 541/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 542/600\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 543/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 544/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 545/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 546/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0025\n",
      "Epoch 547/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 548/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 549/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 550/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 551/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 552/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 553/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 554/600\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0049 - val_loss: 0.0024\n",
      "Epoch 555/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 556/600\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 557/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 558/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 559/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 560/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 561/600\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 562/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 563/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 564/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 565/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 566/600\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 567/600\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 568/600\n",
      "33/33 [==============================] - 1s 28ms/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 569/600\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 570/600\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 571/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 572/600\n",
      "33/33 [==============================] - 2s 68ms/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 573/600\n",
      "33/33 [==============================] - 1s 45ms/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 574/600\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 575/600\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 576/600\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 577/600\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 578/600\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 579/600\n",
      "33/33 [==============================] - 1s 21ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 580/600\n",
      "33/33 [==============================] - 1s 26ms/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 581/600\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 582/600\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 583/600\n",
      "33/33 [==============================] - 1s 19ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 584/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 585/600\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 586/600\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 587/600\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 588/600\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 589/600\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 590/600\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 591/600\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 592/600\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 593/600\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 594/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 595/600\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 596/600\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 597/600\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 598/600\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 599/600\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 600/600\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.0033 - val_loss: 0.0023\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xdae9e5c0d0>"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\r\n",
    "model_loss.plot()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "metadata": {},
     "execution_count": 38
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "predictions = model.predict_classes(X_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\pravirpolly\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "print(classification_report(y_test, predictions))\r\n",
    "# accuracy is good measure for this model because the cancerous vs benign was a blanced or close to balanced"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       200\n",
      "           1       1.00      1.00      1.00       143\n",
      "\n",
      "    accuracy                           1.00       343\n",
      "   macro avg       1.00      1.00      1.00       343\n",
      "weighted avg       1.00      1.00      1.00       343\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "print(confusion_matrix(y_test, predictions))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[200   0]\n",
      " [  0 143]]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "ee5cc6fef2d70a7e71ee3826687cbd150f18158e0b1eef11d4f4f92bb920e304"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}